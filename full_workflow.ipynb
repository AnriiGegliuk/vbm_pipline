{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from modalities.test_mask_segment import  segment_brain_images, mask_brain_images\n",
    "from modalities.report_segmentation import traverse_and_generate_report\n",
    "\n",
    "def run_segmentation_and_masking(input_folder: str, tpm_path: str):\n",
    "    # searching for .nii files within the subdirectories of input_folder\n",
    "    subject_ids = []\n",
    "    for root, _, files in os.walk(input_folder):\n",
    "        for file in files:\n",
    "            if file.endswith('.nii'):\n",
    "                subject_ids.append(os.path.join(root, file))\n",
    "    \n",
    "    print(subject_ids)  # check .nii files\n",
    "\n",
    "    for input_file in subject_ids:\n",
    "        subject_id = os.path.basename(input_file).split('.')[0]\n",
    "        subject_folder = os.path.dirname(input_file)\n",
    "        segmentation_folder = os.path.join(subject_folder, 'segmentation')\n",
    "        os.makedirs(segmentation_folder, exist_ok=True)\n",
    "        \n",
    "        for iteration in range(1, 4):\n",
    "            segmentation_output = segment_brain_images(input_file, tpm_path, iteration, subject_id, subject_folder)\n",
    "            if not segmentation_output:\n",
    "                print(f\"Segmentation failed for {input_file} in iteration {iteration}\")\n",
    "                break\n",
    "            mask_output = mask_brain_images(os.path.join(segmentation_folder, f'{iteration}_segment'), subject_folder, subject_id, iteration)\n",
    "            input_file = os.path.join(segmentation_folder, f'{iteration}_mask', f'masked_{subject_id}.nii')\n",
    "            \n",
    "            # renaming the masked output to the original file name for the next iter\n",
    "            next_input_file = os.path.join(segmentation_folder, f'{iteration}_mask', f'{subject_id}.nii') \n",
    "            os.rename(input_file, next_input_file)\n",
    "            input_file = next_input_file\n",
    "    \n",
    "    # Generate the report after all subjects have been processed\n",
    "    traverse_and_generate_report(input_folder, input_folder)\n",
    "\n",
    "# Example usage:\n",
    "input_folder = 'data/analysis_conditions/'\n",
    "tpm_path = 'data/TPM'\n",
    "run_segmentation_and_masking(input_folder, tpm_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dartel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "from modalities.dartel import create_dartel_structure, perform_dartel, copy_segment_files, find_subject_id\n",
    "\n",
    "def main(base_path: str):\n",
    "    condition_folders = [folder for folder in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, folder))]\n",
    "    dartel_dir = create_dartel_structure(base_path)\n",
    "    copy_segment_files(base_path, condition_folders, dartel_dir)\n",
    "    perform_dartel(dartel_dir)\n",
    "\n",
    "main('/home/sharapova/vbm_pipline/data/analysis_conditions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "from modalities.normalization import normalize_brain_images\n",
    "\n",
    "root_derivatives_dir_path = os.path.abspath('data/analysis_/control_analysis/')\n",
    "output_files = normalize_brain_images(root_derivatives_dir_path)\n",
    "print(output_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "from modalities.smoothing import smooth_brain_images\n",
    "\n",
    "root_derivatives_dir_path = os.path.abspath('/home/sharapova/vbm_pipline/data/analysis_conditions')\n",
    "\n",
    "# Define the full width at half maximum (FWHM) for smoothing\n",
    "fwhm = [3, 3, 3] \n",
    "\n",
    "\n",
    "output_files = smooth_brain_images(root_derivatives_dir_path, fwhm)\n",
    "print(output_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical modeling and estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "from modalities.statistical_modeling_t_test_model import create_two_sample_t_test_model\n",
    "\n",
    "contrasts_name = 'example_contrast_new_logic'\n",
    "output_files = create_two_sample_t_test_model('/home/sharapova/vbm_pipline/data/analysis_conditions', contrasts_name)\n",
    "print(output_files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
